# UPDATE NOTICE
Both paper and code were re-worked and will soon be updated to the latest version

# POV Learning: Individual Alignment of Multimodal Models using Human Perception
This repository contains the code to recreate the experiments from the preprint (https://arxiv.org/pdf/2405.04443)


# Crossmodal-Entailment

- environment.yml contains the conda environment with all necessary packages

- to train, save and evaluate the models with the configurations mentioned in the paper, unzip the contents in the visual_genome_image_features folder and execute the modelCreation.sh file

- preprocess.py requires a different pytorch version (1.12. or higher)

- the image data files for the gpt4_study are not included yet.

- naturally, the OpenAI API Key is also not included
